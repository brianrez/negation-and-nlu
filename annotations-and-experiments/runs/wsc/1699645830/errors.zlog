{"data": "Traceback (most recent call last):\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/jiant/utils/zlog.py\", line 39, in log_context\n    yield self\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/jiant/proj/main/runscript.py\", line 171, in run_loop\n    metarunner.run_train_loop()\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/jiant/shared/metarunner.py\", line 38, in run_train_loop\n    for _ in self.yield_train_step():\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/jiant/proj/main/metarunner.py\", line 109, in yield_train_step\n    for train_state in train_iterator:\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/jiant/proj/main/runner.py\", line 75, in run_train_context\n    self.run_train_step(\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/jiant/proj/main/runner.py\", line 104, in run_train_step\n    model_output = wrap_jiant_forward(\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/jiant/proj/main/modeling/primary.py\", line 107, in wrap_jiant_forward\n    jiant_model(\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 184, in forward\n    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 189, in replicate\n    return replicate(module, device_ids, not torch.is_grad_enabled())\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/torch/nn/parallel/replicate.py\", line 110, in replicate\n    param_copies = _broadcast_coalesced_reshape(params, devices, detach)\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/torch/nn/parallel/replicate.py\", line 83, in _broadcast_coalesced_reshape\n    tensor_copies = Broadcast.apply(devices, *tensors)\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/torch/autograd/function.py\", line 539, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/torch/nn/parallel/_functions.py\", line 23, in forward\n    outputs = comm.broadcast_coalesced(inputs, ctx.target_gpus)\n  File \"/home/cc/negation-and-nlu/tasks/lib/python3.8/site-packages/torch/nn/parallel/comm.py\", line 57, in broadcast_coalesced\n    return torch._C._broadcast_coalesced(tensors, devices, buffer_size)\nRuntimeError: NCCL Error 2: unhandled system error (run with NCCL_DEBUG=INFO for details)\n", "TIMESTAMP": 1699645836.4010212}
